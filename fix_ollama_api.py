#!/usr/bin/env python3
"""
Ollama API Compatibility Fixer
==============================
Testet und behebt Ollama API-Endpunkt Probleme (Windows/macOS Unterschiede)
"""

import requests
import json
import sys

def test_ollama_endpoints():
    print("üîß OLLAMA API COMPATIBILITY TEST")
    print("=" * 50)
    
    base_url = "http://localhost:11434"
    
    # Test basic connectivity
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Ollama service is running")
            models = response.json().get('models', [])
            print(f"üìä Available models: {len(models)}")
        else:
            print("‚ùå Ollama service not responding")
            return False
    except Exception as e:
        print(f"‚ùå Cannot connect to Ollama: {e}")
        return False
    
    # Test embedding endpoint (new API only since embeddinggemma requires Ollama >= 0.11.10)
    test_payload = {
        "model": "embeddinggemma",
        "prompt": "test embedding"
    }
    
    endpoint = "/api/embed"
    description = "Ollama API (requires v0.11.10+)"
    
    print(f"\nüß™ Testing {description}...")
    print(f"   URL: {base_url}{endpoint}")
    
    try:
        response = requests.post(
            f"{base_url}{endpoint}",
            json=test_payload,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            embedding = result.get('embedding', [])
            if embedding and len(embedding) > 0:
                print(f"   ‚úÖ SUCCESS: Got {len(embedding)}-dimensional embedding")
                working_endpoint = endpoint
            else:
                print("   ‚ö†Ô∏è  Response OK but empty embedding")
        elif response.status_code == 404:
            print(f"   ‚ùå 404 Not Found - Ollama version too old!")
            print(f"   üí° Please update Ollama to >= 0.11.10")
            print(f"   üîß Run: curl -fsSL https://ollama.ai/install.sh | sh")
        else:
            print(f"   ‚ùå HTTP {response.status_code}: {response.text[:100]}")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    if working_endpoint:
        print(f"\nüéâ SOLUTION FOUND!")
        print(f"‚úÖ Working endpoint: {working_endpoint}")
        print(f"üí° Your AI PDF Processor will use this endpoint")
        return True
    else:
        print(f"\n‚ùå EMBEDDING API NOT WORKING!")
        print(f"üîß Required: Ollama >= 0.11.10 with embeddinggemma model")
        print(f"üîß Troubleshooting steps:")
        print(f"   1. Update Ollama: curl -fsSL https://ollama.ai/install.sh | sh")
        print(f"   2. Restart Ollama service")
        print(f"   3. Install model: ollama pull embeddinggemma")
        return False

def check_ollama_version():
    """Check Ollama version for compatibility info"""
    try:
        response = requests.get("http://localhost:11434/api/version", timeout=5)
        if response.status_code == 200:
            version_info = response.json()
            print(f"\nüìã Ollama Version Info:")
            print(f"   Version: {version_info.get('version', 'Unknown')}")
            return version_info
    except:
        print(f"\n‚ö†Ô∏è  Could not get Ollama version info")
    return None

if __name__ == "__main__":
    print("Starting Ollama API compatibility test...")
    
    # Check version first
    check_ollama_version()
    
    # Test endpoints
    success = test_ollama_endpoints()
    
    if success:
        print(f"\nüöÄ Your system is ready for AI PDF processing!")
    else:
        print(f"\nüõ†Ô∏è  Please fix Ollama setup before proceeding")
        sys.exit(1)